{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3CLwmlWipMu",
        "colab_type": "code",
        "outputId": "e0cb0cea-dff1-4251-dc17-569d9dcb8a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "\n",
        "#connect to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcD_oftLoaiw",
        "colab_type": "code",
        "outputId": "446c81d6-3827-4ffc-b289-d0ea14516421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#go to data path\n",
        "cd 'drive/My Drive/Colab Notebooks'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5L_oA45vCCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip 'data.zip'   used once to uncompress data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IkOCwtro2ZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load Data\n",
        "def load_data(train_path):\n",
        "    X=np.array([])\n",
        "    y=[]\n",
        "    \n",
        "    for label in listdir(train_path):\n",
        "        for i in listdir(train_path+label+'/'):\n",
        "          image_path = train_path+label+'/'+i\n",
        "          img = cv2.imread(image_path)\n",
        "          img=cv2.resize(img,(256, 256))\n",
        "          img=  np.array(img)\n",
        "          img=img.reshape(1,3,img.shape[0],img.shape[1])\n",
        "          #print('image shape:',img.shape)\n",
        "          X = np.vstack([X, img]) if X.size else img\n",
        "          y.append(label)\n",
        "          #print(img, label)\n",
        "    #print(\"X\",X.shape,\"y\",len(y))\n",
        "         \n",
        "    #categorize the labels\n",
        "    labeincoder_y_1 = LabelEncoder()\n",
        "    y[: ] = labeincoder_y_1.fit_transform(y[: ])\n",
        "    X = np.asarray(X)\n",
        "    #print(\"Yenconded\",y)\n",
        "    #print(\"Y\",y,len(y))\n",
        "    #print(\"X\",X,X.shape)\n",
        "    # split the data into a training set and a test set\n",
        "    # stratify returns training and test subsets that have the same proportions of class labels as the input dataset.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,stratify=y)  \n",
        "    X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size = 0.25,stratify=y_train)\n",
        "    \n",
        "    #to give weights to balance the classes labels\n",
        "    class_weights = compute_class_weight('balanced', np.unique(y_train),y_train)\n",
        "    \n",
        "    #print(\"train test\",X_train,len(X_train), X_test,len(X_test), y_train, y_test)\n",
        "    return X,y,X_train, X_test, y_train, y_test,X_dev, y_dev,labeincoder_y_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xlq4zR5qbro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DL_model (data_train, data_test, label_train, label_test,data_valed, label_valed,path_test):\n",
        "  name=[]\n",
        "  result=[]\n",
        "  K.set_image_dim_ordering('th')\n",
        "\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(3, 256, 256)))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(9))\n",
        "  model.add(Activation('softmax'))\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer='rmsprop',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model.fit(data_train, np.asarray(label_train),\n",
        "            batch_size=32,\n",
        "            validation_data=(data_valed, np.asarray(label_valed)),\n",
        "            epochs=100)\n",
        "\n",
        "\n",
        "  #evaluate model\n",
        "  loss, acc = model.evaluate(data_test, np.asarray(label_test))\n",
        "  print(\"loss:\",loss,\"accuracy:\", acc)\n",
        "  \n",
        "  # serialize model to JSON\n",
        "  model_json = model.to_json()\n",
        "  with open(\"model.json\", \"w\") as json_file:\n",
        "      json_file.write(model_json)\n",
        "  # serialize weights to HDF5\n",
        "  model.save_weights(\"model.h5\")\n",
        "  print(\"Saved model to disk\")\n",
        " \n",
        "  #classify unlabeled Data\n",
        "  \n",
        "  X2 = []\n",
        "  ids = []\n",
        "  for i in listdir(path_test+'/'):\n",
        "      img = cv2.imread(path_test+'/'+i)\n",
        "      img=cv2.resize(img,(256, 256))\n",
        "      img=  np.array(img)\n",
        "      img=img.reshape(3,img.shape[0],img.shape[1])\n",
        "      X2.append(img)\n",
        "      ids.append(i)\n",
        "  X2 = np.asarray(X2)\n",
        "#       X2 = np.vstack([X2, img]) if X2.size else img\n",
        "  preds=model.predict_classes(X2, batch_size=64, verbose=0)\n",
        "  result=label_encoder.inverse_transform(preds)  \n",
        "#       print(i,result)\n",
        "#       name.append(i)\n",
        "#       result.append(result)\n",
        "  np.savetxt('results.csv', [p for p in zip(ids, result)], delimiter=',', fmt='%s')\n",
        "      \n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlrDDWA3oZLL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvLmDNSelIuR",
        "colab_type": "code",
        "outputId": "e2c07a01-50c5-4ef7-be72-877c2538fa71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3522
        }
      },
      "source": [
        "#importing libraries\n",
        "import cv2\n",
        "import csv\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "path_train ='train-data/'\n",
        "path_test  ='test-data/'\n",
        "data_to_train,label,data_train, data_test, label_train, label_test,data_valed, label_valed,label_encoder=load_data(path_train)\n",
        "print(\"train\",data_train.shape,\"test\",data_test.shape,\"label\",label)\n",
        "\n",
        "DL_model (data_train, data_test, label_train, label_test,data_valed, label_valed,path_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train (278, 3, 256, 256) test (124, 3, 256, 256) label [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Train on 278 samples, validate on 93 samples\n",
            "Epoch 1/100\n",
            "278/278 [==============================] - 4s 15ms/step - loss: 4.4217 - acc: 0.1511 - val_loss: 2.6143 - val_acc: 0.1505\n",
            "Epoch 2/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 2.3646 - acc: 0.1259 - val_loss: 2.1306 - val_acc: 0.1613\n",
            "Epoch 3/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 2.2121 - acc: 0.1835 - val_loss: 2.3940 - val_acc: 0.1505\n",
            "Epoch 4/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 2.2316 - acc: 0.1403 - val_loss: 2.0888 - val_acc: 0.2151\n",
            "Epoch 5/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 2.1804 - acc: 0.1799 - val_loss: 2.0909 - val_acc: 0.2043\n",
            "Epoch 6/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 2.1615 - acc: 0.1799 - val_loss: 2.1266 - val_acc: 0.2796\n",
            "Epoch 7/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 2.0032 - acc: 0.2590 - val_loss: 2.2608 - val_acc: 0.3118\n",
            "Epoch 8/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 2.0443 - acc: 0.2734 - val_loss: 1.9861 - val_acc: 0.3441\n",
            "Epoch 9/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 2.0826 - acc: 0.2518 - val_loss: 2.2114 - val_acc: 0.3011\n",
            "Epoch 10/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.9173 - acc: 0.2734 - val_loss: 2.0878 - val_acc: 0.3226\n",
            "Epoch 11/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 2.0068 - acc: 0.2590 - val_loss: 2.6296 - val_acc: 0.1505\n",
            "Epoch 12/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 2.0197 - acc: 0.2266 - val_loss: 1.9078 - val_acc: 0.3226\n",
            "Epoch 13/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.8616 - acc: 0.3237 - val_loss: 3.1405 - val_acc: 0.2151\n",
            "Epoch 14/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.9263 - acc: 0.2626 - val_loss: 2.0161 - val_acc: 0.3011\n",
            "Epoch 15/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.8550 - acc: 0.3345 - val_loss: 2.2082 - val_acc: 0.1935\n",
            "Epoch 16/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.8124 - acc: 0.3453 - val_loss: 2.6371 - val_acc: 0.2366\n",
            "Epoch 17/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.8666 - acc: 0.3381 - val_loss: 1.8411 - val_acc: 0.2581\n",
            "Epoch 18/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.7082 - acc: 0.3453 - val_loss: 1.8890 - val_acc: 0.3441\n",
            "Epoch 19/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.7921 - acc: 0.3237 - val_loss: 1.8340 - val_acc: 0.3548\n",
            "Epoch 20/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.8159 - acc: 0.3705 - val_loss: 3.2850 - val_acc: 0.2581\n",
            "Epoch 21/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.6791 - acc: 0.3633 - val_loss: 1.7750 - val_acc: 0.3548\n",
            "Epoch 22/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.6807 - acc: 0.3633 - val_loss: 1.7876 - val_acc: 0.3118\n",
            "Epoch 23/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.6856 - acc: 0.3453 - val_loss: 1.8340 - val_acc: 0.3011\n",
            "Epoch 24/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.7269 - acc: 0.3489 - val_loss: 1.8502 - val_acc: 0.4086\n",
            "Epoch 25/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.6375 - acc: 0.4568 - val_loss: 1.8178 - val_acc: 0.3118\n",
            "Epoch 26/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.5531 - acc: 0.4137 - val_loss: 2.4727 - val_acc: 0.2796\n",
            "Epoch 27/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.6552 - acc: 0.3957 - val_loss: 2.0198 - val_acc: 0.3226\n",
            "Epoch 28/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.5823 - acc: 0.4065 - val_loss: 2.0130 - val_acc: 0.3118\n",
            "Epoch 29/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.6049 - acc: 0.4568 - val_loss: 1.9702 - val_acc: 0.3333\n",
            "Epoch 30/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.5484 - acc: 0.4676 - val_loss: 2.3389 - val_acc: 0.3441\n",
            "Epoch 31/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.4609 - acc: 0.4496 - val_loss: 1.9877 - val_acc: 0.3226\n",
            "Epoch 32/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.4995 - acc: 0.4388 - val_loss: 2.2965 - val_acc: 0.2796\n",
            "Epoch 33/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.4485 - acc: 0.4748 - val_loss: 2.0628 - val_acc: 0.3656\n",
            "Epoch 34/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.3665 - acc: 0.5252 - val_loss: 2.0930 - val_acc: 0.3441\n",
            "Epoch 35/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.4202 - acc: 0.5000 - val_loss: 2.0141 - val_acc: 0.2796\n",
            "Epoch 36/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.3729 - acc: 0.4748 - val_loss: 2.1898 - val_acc: 0.3226\n",
            "Epoch 37/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.2812 - acc: 0.5360 - val_loss: 2.5011 - val_acc: 0.3118\n",
            "Epoch 38/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.3718 - acc: 0.4892 - val_loss: 2.4873 - val_acc: 0.3226\n",
            "Epoch 39/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.3683 - acc: 0.5036 - val_loss: 2.0095 - val_acc: 0.4194\n",
            "Epoch 40/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.2784 - acc: 0.5288 - val_loss: 1.8552 - val_acc: 0.3871\n",
            "Epoch 41/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.2238 - acc: 0.5504 - val_loss: 2.1363 - val_acc: 0.3548\n",
            "Epoch 42/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.3668 - acc: 0.4964 - val_loss: 2.7261 - val_acc: 0.2903\n",
            "Epoch 43/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.0737 - acc: 0.6295 - val_loss: 2.3902 - val_acc: 0.3011\n",
            "Epoch 44/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.4159 - acc: 0.5108 - val_loss: 7.0247 - val_acc: 0.1398\n",
            "Epoch 45/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.2075 - acc: 0.5935 - val_loss: 3.1735 - val_acc: 0.3333\n",
            "Epoch 46/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.9366 - acc: 0.6619 - val_loss: 3.1324 - val_acc: 0.3118\n",
            "Epoch 47/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.9986 - acc: 0.6619 - val_loss: 2.0033 - val_acc: 0.4086\n",
            "Epoch 48/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.8229 - acc: 0.7302 - val_loss: 2.8908 - val_acc: 0.3118\n",
            "Epoch 49/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.0368 - acc: 0.6547 - val_loss: 2.8141 - val_acc: 0.3548\n",
            "Epoch 50/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.8368 - acc: 0.7158 - val_loss: 2.3960 - val_acc: 0.4516\n",
            "Epoch 51/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.8406 - acc: 0.7014 - val_loss: 3.2679 - val_acc: 0.3118\n",
            "Epoch 52/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.0294 - acc: 0.6763 - val_loss: 2.3411 - val_acc: 0.3978\n",
            "Epoch 53/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.7723 - acc: 0.7158 - val_loss: 3.4059 - val_acc: 0.2796\n",
            "Epoch 54/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.9138 - acc: 0.7122 - val_loss: 2.3397 - val_acc: 0.4409\n",
            "Epoch 55/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.7190 - acc: 0.7482 - val_loss: 3.0959 - val_acc: 0.3118\n",
            "Epoch 56/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 1.0766 - acc: 0.6079 - val_loss: 2.2272 - val_acc: 0.4516\n",
            "Epoch 57/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.5352 - acc: 0.8381 - val_loss: 2.5425 - val_acc: 0.3978\n",
            "Epoch 58/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.6799 - acc: 0.7590 - val_loss: 6.5499 - val_acc: 0.2043\n",
            "Epoch 59/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.7657 - acc: 0.7302 - val_loss: 2.8841 - val_acc: 0.3548\n",
            "Epoch 60/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.5650 - acc: 0.8058 - val_loss: 2.5375 - val_acc: 0.4086\n",
            "Epoch 61/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.6197 - acc: 0.7914 - val_loss: 2.7349 - val_acc: 0.4301\n",
            "Epoch 62/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.5578 - acc: 0.8022 - val_loss: 2.7696 - val_acc: 0.3656\n",
            "Epoch 63/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.5417 - acc: 0.8201 - val_loss: 2.7800 - val_acc: 0.3763\n",
            "Epoch 64/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.5147 - acc: 0.8058 - val_loss: 3.2073 - val_acc: 0.3656\n",
            "Epoch 65/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4626 - acc: 0.8129 - val_loss: 2.8663 - val_acc: 0.3548\n",
            "Epoch 66/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3732 - acc: 0.8813 - val_loss: 2.8885 - val_acc: 0.3548\n",
            "Epoch 67/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4309 - acc: 0.8489 - val_loss: 4.1550 - val_acc: 0.3226\n",
            "Epoch 68/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4302 - acc: 0.8561 - val_loss: 6.6242 - val_acc: 0.2903\n",
            "Epoch 69/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.6166 - acc: 0.8129 - val_loss: 3.4674 - val_acc: 0.3871\n",
            "Epoch 70/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.2924 - acc: 0.8813 - val_loss: 3.5582 - val_acc: 0.3011\n",
            "Epoch 71/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4843 - acc: 0.8561 - val_loss: 4.6664 - val_acc: 0.3763\n",
            "Epoch 72/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.2567 - acc: 0.9281 - val_loss: 8.6632 - val_acc: 0.2903\n",
            "Epoch 73/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.5326 - acc: 0.8669 - val_loss: 4.8490 - val_acc: 0.3118\n",
            "Epoch 74/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.6150 - acc: 0.8345 - val_loss: 2.9150 - val_acc: 0.3871\n",
            "Epoch 75/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.1683 - acc: 0.9424 - val_loss: 3.2121 - val_acc: 0.3441\n",
            "Epoch 76/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.2074 - acc: 0.9317 - val_loss: 5.0417 - val_acc: 0.3763\n",
            "Epoch 77/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.5290 - acc: 0.8201 - val_loss: 5.8829 - val_acc: 0.3118\n",
            "Epoch 78/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.2485 - acc: 0.9101 - val_loss: 4.6667 - val_acc: 0.3656\n",
            "Epoch 79/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.2002 - acc: 0.9388 - val_loss: 3.4579 - val_acc: 0.4409\n",
            "Epoch 80/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.2624 - acc: 0.8849 - val_loss: 3.6968 - val_acc: 0.4086\n",
            "Epoch 81/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4671 - acc: 0.8597 - val_loss: 4.0521 - val_acc: 0.3978\n",
            "Epoch 82/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.2677 - acc: 0.9209 - val_loss: 3.7010 - val_acc: 0.3226\n",
            "Epoch 83/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.1674 - acc: 0.9353 - val_loss: 3.6360 - val_acc: 0.4086\n",
            "Epoch 84/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.1556 - acc: 0.9460 - val_loss: 4.3559 - val_acc: 0.4194\n",
            "Epoch 85/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.6438 - acc: 0.8165 - val_loss: 6.6212 - val_acc: 0.3871\n",
            "Epoch 86/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.1325 - acc: 0.9532 - val_loss: 5.6381 - val_acc: 0.3656\n",
            "Epoch 87/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.1695 - acc: 0.9388 - val_loss: 5.3231 - val_acc: 0.3656\n",
            "Epoch 88/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.2098 - acc: 0.9281 - val_loss: 5.2124 - val_acc: 0.3226\n",
            "Epoch 89/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.1383 - acc: 0.9532 - val_loss: 4.7195 - val_acc: 0.3656\n",
            "Epoch 90/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.1457 - acc: 0.9532 - val_loss: 5.7424 - val_acc: 0.3333\n",
            "Epoch 91/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.2348 - acc: 0.9065 - val_loss: 3.8627 - val_acc: 0.4301\n",
            "Epoch 92/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.2081 - acc: 0.9353 - val_loss: 5.7415 - val_acc: 0.3441\n",
            "Epoch 93/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.4197 - acc: 0.8957 - val_loss: 6.1496 - val_acc: 0.2903\n",
            "Epoch 94/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.0981 - acc: 0.9712 - val_loss: 4.0771 - val_acc: 0.3333\n",
            "Epoch 95/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.0643 - acc: 0.9712 - val_loss: 4.6731 - val_acc: 0.3763\n",
            "Epoch 96/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.3637 - acc: 0.9029 - val_loss: 4.3339 - val_acc: 0.3978\n",
            "Epoch 97/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.1169 - acc: 0.9568 - val_loss: 4.8845 - val_acc: 0.3763\n",
            "Epoch 98/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.1139 - acc: 0.9353 - val_loss: 4.4048 - val_acc: 0.3763\n",
            "Epoch 99/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.1088 - acc: 0.9712 - val_loss: 4.2966 - val_acc: 0.4086\n",
            "Epoch 100/100\n",
            "278/278 [==============================] - 1s 3ms/step - loss: 0.0650 - acc: 0.9748 - val_loss: 3.7136 - val_acc: 0.4194\n",
            "124/124 [==============================] - 0s 1ms/step\n",
            "loss: 3.6493979884732153 accuracy: 0.43548386904501146\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}